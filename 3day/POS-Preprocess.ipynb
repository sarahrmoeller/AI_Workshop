{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d99cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint, time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b20975",
   "metadata": {},
   "source": [
    "# Get Data\n",
    "\n",
    "Get training and test data from `_T` files. Get incomplete annotations from `_U` files.\n",
    "Write three data sets to files for printing and sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8605277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata(filepath):\n",
    "    X_all = [line.strip() for line in open(filepath+'.input')]\n",
    "    y_all = [line.strip() for line in open(filepath+'.output')]\n",
    "    return X_all, y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5bd28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(trainlabels):\n",
    "    # List all POS tags used in the data\n",
    "    taglist = [tag for sent in trainlabels for tag in sent.split()]\n",
    "    tagset = list(set(taglist))\n",
    "    tokens = len(trainlabels)\n",
    "    sorted_tags = sorted(Counter(taglist).items(), key=lambda x:x[1], reverse=True)\n",
    "    sort_string = ''\n",
    "    for tag,val in sorted_tags:\n",
    "        sort_string += \"{: <10}\\t{}\\n\".format(tag, val)\n",
    "        \n",
    "    tagreport = \"Tags in training data:\\n\" + ', '.join(tagset) + '\\n'\n",
    "    tokenreport = str(tokens) + \" training tokens\"  + '\\n'\n",
    "    tagcounts = \"Frequency of tags in training data:\\n\" + sort_string  + '\\n'\n",
    "    print(tagreport)\n",
    "    print(tokenreport)\n",
    "    print(tagcounts)\n",
    "    \n",
    "    return tagreport+tokenreport+tagcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f2ae68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def POS2file(xlist, ylist, filepath):\n",
    "    '''Format data for human readable files'''\n",
    "    line_tuples = list(zip(xlist, ylist))\n",
    "    data = []\n",
    "    for sent in line_tuples:\n",
    "        pairs = zip(sent[0].split(), sent[1].split())\n",
    "        data.append(' '.join([word+SEPARATOR+tag for word,tag in pairs]))\n",
    "\n",
    "    with open(filepath, 'w') as T:\n",
    "        T.write('\\n'.join(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7ecef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''write data sets to files for printing and sharing\n",
    "    Remove POS tags if data is supposed to be unannotated'''\n",
    "    \n",
    "    X_unannotated, y_unannotated = getdata(FROMDIR+LANG+'_U'+TASK)\n",
    "    X_annotated, y_annotated = getdata(FROMDIR+LANG+'_T'+TASK)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_annotated, y_annotated, test_size=.1, random_state=42)\n",
    "    \n",
    "    if TASK == '_pos':\n",
    "        POS2file(X_train, y_train, DATADIR+CRF_FILENAME+'0.train')\n",
    "        POS2file(X_test, y_test, DATADIR+CRF_FILENAME+'0.test')\n",
    "        POS2file(X_unannotated, y_unannotated, DATADIR+CRF_FILENAME+'.predict')\n",
    "        with open(REPORTDIR+CRF_FILENAME+'_log.txt', 'w') as l:\n",
    "            l.write(CRF_FILENAME + '\\n\\n' + stats(y_train))\n",
    "            \n",
    "        POS2file(X_train, y_train, DATADIR+TRANSFORMER_FILENAME+'0.train')\n",
    "        POS2file(X_test, y_test, DATADIR+TRANSFORMER_FILENAME+'0.test')\n",
    "        POS2file(X_unannotated, y_unannotated, DATADIR+TRANSFORMER_FILENAME+'.predict')\n",
    "        with open(REPORTDIR+TRANSFORMER_FILENAME+'_log.txt', 'w') as l:\n",
    "            l.write(TRANSFORMER_FILENAME + '\\n\\n' + stats(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5192ecad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags in training data:\n",
      "nvp, nprop, proform, cardnum, imp, dir, dem, post, DM, pro, interj, adv, advlizer, PUNCT, verbprt, mod, quant, v, inter, n, nomprt, onom, NUM, adj, coordconn\n",
      "\n",
      "960 training tokens\n",
      "\n",
      "Frequency of tags in training data:\n",
      "v         \t1443\n",
      "PUNCT     \t1187\n",
      "n         \t889\n",
      "post      \t470\n",
      "adv       \t356\n",
      "coordconn \t320\n",
      "advlizer  \t273\n",
      "dir       \t168\n",
      "DM        \t166\n",
      "proform   \t162\n",
      "nomprt    \t126\n",
      "verbprt   \t72\n",
      "inter     \t69\n",
      "mod       \t57\n",
      "nvp       \t43\n",
      "interj    \t38\n",
      "pro       \t24\n",
      "cardnum   \t21\n",
      "quant     \t17\n",
      "dem       \t15\n",
      "adj       \t10\n",
      "imp       \t3\n",
      "NUM       \t2\n",
      "onom      \t1\n",
      "nprop     \t1\n",
      "\n",
      "\n",
      "Tags in training data:\n",
      "nvp, nprop, proform, cardnum, imp, dir, dem, post, DM, pro, interj, adv, advlizer, PUNCT, verbprt, mod, quant, v, inter, n, nomprt, onom, NUM, adj, coordconn\n",
      "\n",
      "960 training tokens\n",
      "\n",
      "Frequency of tags in training data:\n",
      "v         \t1443\n",
      "PUNCT     \t1187\n",
      "n         \t889\n",
      "post      \t470\n",
      "adv       \t356\n",
      "coordconn \t320\n",
      "advlizer  \t273\n",
      "dir       \t168\n",
      "DM        \t166\n",
      "proform   \t162\n",
      "nomprt    \t126\n",
      "verbprt   \t72\n",
      "inter     \t69\n",
      "mod       \t57\n",
      "nvp       \t43\n",
      "interj    \t38\n",
      "pro       \t24\n",
      "cardnum   \t21\n",
      "quant     \t17\n",
      "dem       \t15\n",
      "adj       \t10\n",
      "imp       \t3\n",
      "NUM       \t2\n",
      "onom      \t1\n",
      "nprop     \t1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LANG = 'tau'\n",
    "TASK = '_pos'\n",
    "\n",
    "FROMDIR = r'../../'+LANG+'/'\n",
    "DATADIR = r'../../'+LANG+'/data/'\n",
    "REPORTDIR = r'../../'+LANG+'/reports/'\n",
    "\n",
    "TRANSFORMER_FILENAME = LANG+TASK+'Trans'\n",
    "CRF_FILENAME = LANG+TASK+'CRF'\n",
    "\n",
    "SEPARATOR = '|'\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86927cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
