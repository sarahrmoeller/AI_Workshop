Questıons and problems after first test run
initial setting of training data/test was 0.1

1. Output image: why is there a 100% confusion between nouns and adjectives (all adjectives as nouns?

2. If we find a recurring mistake, how do we get the machine to fix it? Can it be changed by readjusting algorithm values? (Aggression level)

overall accuracy is 0.71. Ideas for improvement
1. change ratio of training and testing data
2. change algorithm of CRF

Second run: 
we're changing the ratio of training and testing data to be training data was 0.7 -> this improved it a little but not across all categories

Third run: 
going back to the original setting (test 0.1) but we removed the category VCL

noticed that there is a  miscategorization with adjectives (and everything else)

Olga L went and checked the so-called gold standard. New files (ending in POS4) were sent to Olga K.

New round on 2023-11-15. Attempt4

THIS IS NOW OUR FIRST ATTEMPT. We cleaned up the data, now thıngs are better. We took the 12 or so most confused lınes and manually fıxed them and pasted them ınto the traınıng set.

Attempt5 

it became slightly better but not great.

now we're playing with features in the code. We remove suffixes as something to worry about but tell it to look at prefixes a bit more: 7 characters rather than 4. Take out stemming.

Everything got slightly worse except for INTV. 

Plan for tomorrow: we put "stemming" back in because that shouldn't have an effect. 
If "stemming" has an effect, something weird is going on that we need to investigate.
If "stemming" has no effect, then we reduce the number of prefixes. 

New round on 2023-11-16
- stemming indeed has no effect whatsoever. Increasing the prefixes gave us better results for verbs, adding some suffixes gave us an improvement to 0.74 overall accuracy.

We started adding TaneshaLEM and that took a while to get into the correct set. That brought us to 

ATTEMPT11

where Olga L fixed up some of the results.

We decided to add UNK for unknown, as well as ART for article

In the next round, we plan to add AUX for auxiliary to deal with the English data
